{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Asssignment_5_EIP.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahulin05/EIP-4/blob/master/Week-5/Asssignment_5_EIP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FrLoXYngmRI",
        "colab_type": "code",
        "outputId": "c2088c25-4122-449a-8b27-484b67deec93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# mount gdrive and unzip data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmmS_aF3gwfo",
        "colab_type": "code",
        "outputId": "a3409ed8-1764-4b02-a42a-4fb79d8d744e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "os.listdir(\".\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'gdrive', 'sample_data']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvuU9_rTg0k8",
        "colab_type": "code",
        "outputId": "186e1825-56cf-4ca1-d4d6-71d1f0c6f5c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!unzip -q \"/content/gdrive/My Drive/hvc_data.zip\"\n",
        "# look for `hvc_annotations.csv` file and `resized` dir\n",
        "%ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mgdrive\u001b[0m/  hvc_annotations.csv  \u001b[01;34mresized\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEp9nlQohLBf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade --upgrade-strategy only-if-needed https://github.com/faizanahemad/data-science-utils/tarball/master > /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9GVE2SLhfDh",
        "colab_type": "code",
        "outputId": "c2bc2e04-6446-4e7e-f5df-bfc346f092a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-pr4j2g5w\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-pr4j2g5w\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-contrib==2.0.8) (2.2.5)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.17.4)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.3.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (2.8.0)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp36-none-any.whl size=101065 sha256=ea433b89358f400ffc81e3e618a0bead48c0cb055781fc6b7ff53373cd6061e8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1k0fh4fo/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T6_9gH8hkFi",
        "colab_type": "code",
        "outputId": "3261b88a-833e-47fa-a3cd-0347a1f8b9e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "import cv2\n",
        "import json\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from functools import partial\n",
        "from pathlib import Path \n",
        "from tqdm import tqdm\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.applications import VGG16\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Input, Conv2D, MaxPool2D\n",
        "from keras.layers import AveragePooling2D, Input, Flatten, Activation, Flatten, Dropout, SeparableConv2D, GlobalAveragePooling2D\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from keras.regularizers import l2\n",
        "\n",
        "\n",
        "from albumentations import (\n",
        "    Compose, HorizontalFlip, ToFloat, ShiftScaleRotate,\n",
        "    Normalize, Rotate, Cutout\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfnSoNfOhvmW",
        "colab_type": "code",
        "outputId": "10049558-ceb3-4200-d45e-2df4ee979f8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "# load annotations\n",
        "df = pd.read_csv(\"hvc_annotations.csv\")\n",
        "del df[\"filename\"] # remove unwanted column\n",
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>imagequality</th>\n",
              "      <th>age</th>\n",
              "      <th>weight</th>\n",
              "      <th>carryingbag</th>\n",
              "      <th>footwear</th>\n",
              "      <th>emotion</th>\n",
              "      <th>bodypose</th>\n",
              "      <th>image_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>male</td>\n",
              "      <td>Average</td>\n",
              "      <td>35-45</td>\n",
              "      <td>normal-healthy</td>\n",
              "      <td>Grocery/Home/Plastic Bag</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/1.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>female</td>\n",
              "      <td>Average</td>\n",
              "      <td>35-45</td>\n",
              "      <td>over-weight</td>\n",
              "      <td>None</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Angry/Serious</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/2.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>male</td>\n",
              "      <td>Good</td>\n",
              "      <td>45-55</td>\n",
              "      <td>normal-healthy</td>\n",
              "      <td>Grocery/Home/Plastic Bag</td>\n",
              "      <td>CantSee</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/3.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>male</td>\n",
              "      <td>Good</td>\n",
              "      <td>45-55</td>\n",
              "      <td>normal-healthy</td>\n",
              "      <td>Daily/Office/Work Bag</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/4.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>female</td>\n",
              "      <td>Good</td>\n",
              "      <td>35-45</td>\n",
              "      <td>slightly-overweight</td>\n",
              "      <td>None</td>\n",
              "      <td>CantSee</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/5.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   gender imagequality    age  ...        emotion        bodypose     image_path\n",
              "0    male      Average  35-45  ...        Neutral  Front-Frontish  resized/1.jpg\n",
              "1  female      Average  35-45  ...  Angry/Serious  Front-Frontish  resized/2.jpg\n",
              "2    male         Good  45-55  ...        Neutral  Front-Frontish  resized/3.jpg\n",
              "3    male         Good  45-55  ...        Neutral  Front-Frontish  resized/4.jpg\n",
              "4  female         Good  35-45  ...        Neutral  Front-Frontish  resized/5.jpg\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hm3U2slUh23x",
        "colab_type": "code",
        "outputId": "9a0b9665-bafe-4ff1-e2a0-5329fd4ca1b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(df.groupby(\"gender\")[\"gender\"].count())\n",
        "print(\"Baseline gender accuracy: \"+str(max(df.groupby(\"gender\")[\"gender\"].count())/sum(df.groupby(\"gender\")[\"gender\"].count())))\n",
        "print(\"\\n\")\n",
        "\n",
        "print(df.groupby(\"imagequality\")[\"imagequality\"].count())\n",
        "print(\"Baseline imagequality accuracy: \"+str(max(df.groupby(\"imagequality\")[\"imagequality\"].count())/sum(df.groupby(\"imagequality\")[\"imagequality\"].count())))\n",
        "print(\"\\n\")\n",
        "\n",
        "print(df.groupby(\"age\")[\"age\"].count())\n",
        "print(\"Baseline age accuracy: \"+str(max(df.groupby(\"age\")[\"age\"].count())/sum(df.groupby(\"age\")[\"age\"].count())))\n",
        "print(\"\\n\")\n",
        "\n",
        "print(df.groupby(\"weight\")[\"weight\"].count())\n",
        "print(\"Baseline weight accuracy: \"+str(max(df.groupby(\"weight\")[\"weight\"].count())/sum(df.groupby(\"weight\")[\"weight\"].count())))\n",
        "print(\"\\n\")\n",
        "\n",
        "print(df.groupby(\"carryingbag\")[\"carryingbag\"].count())\n",
        "print(\"Baseline carryingbag accuracy: \"+str(max(df.groupby(\"carryingbag\")[\"carryingbag\"].count())/sum(df.groupby(\"carryingbag\")[\"carryingbag\"].count())))\n",
        "print(\"\\n\")\n",
        "\n",
        "print(df.groupby(\"footwear\")[\"footwear\"].count())\n",
        "print(\"Baseline footwear accuracy: \"+str(max(df.groupby(\"footwear\")[\"footwear\"].count())/sum(df.groupby(\"footwear\")[\"footwear\"].count())))\n",
        "print(\"\\n\")\n",
        "\n",
        "print(df.groupby(\"emotion\")[\"emotion\"].count())\n",
        "print(\"Baseline emotion accuracy: \"+str(max(df.groupby(\"emotion\")[\"emotion\"].count())/sum(df.groupby(\"emotion\")[\"emotion\"].count())))\n",
        "print(\"\\n\")\n",
        "\n",
        "print(df.groupby(\"bodypose\")[\"bodypose\"].count())\n",
        "print(\"Baseline bodypose accuracy: \"+str(max(df.groupby(\"bodypose\")[\"bodypose\"].count())/sum(df.groupby(\"bodypose\")[\"bodypose\"].count())))\n",
        "print(\"\\n\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gender\n",
            "female    5937\n",
            "male      7636\n",
            "Name: gender, dtype: int64\n",
            "Baseline gender accuracy: 0.5625874898695941\n",
            "\n",
            "\n",
            "imagequality\n",
            "Average    7509\n",
            "Bad        2240\n",
            "Good       3824\n",
            "Name: imagequality, dtype: int64\n",
            "Baseline imagequality accuracy: 0.5532306785530097\n",
            "\n",
            "\n",
            "age\n",
            "15-25    2494\n",
            "25-35    5411\n",
            "35-45    3435\n",
            "45-55    1490\n",
            "55+       743\n",
            "Name: age, dtype: int64\n",
            "Baseline age accuracy: 0.39865910263022175\n",
            "\n",
            "\n",
            "weight\n",
            "normal-healthy         8628\n",
            "over-weight             891\n",
            "slightly-overweight    3196\n",
            "underweight             858\n",
            "Name: weight, dtype: int64\n",
            "Baseline weight accuracy: 0.6356737640904737\n",
            "\n",
            "\n",
            "carryingbag\n",
            "Daily/Office/Work Bag       4603\n",
            "Grocery/Home/Plastic Bag    1321\n",
            "None                        7649\n",
            "Name: carryingbag, dtype: int64\n",
            "Baseline carryingbag accuracy: 0.56354527370515\n",
            "\n",
            "\n",
            "footwear\n",
            "CantSee    5028\n",
            "Fancy      2507\n",
            "Normal     6038\n",
            "Name: footwear, dtype: int64\n",
            "Baseline footwear accuracy: 0.4448537537758786\n",
            "\n",
            "\n",
            "emotion\n",
            "Angry/Serious    1500\n",
            "Happy            1609\n",
            "Neutral          9660\n",
            "Sad               804\n",
            "Name: emotion, dtype: int64\n",
            "Baseline emotion accuracy: 0.7117070654976793\n",
            "\n",
            "\n",
            "bodypose\n",
            "Back              2207\n",
            "Front-Frontish    8383\n",
            "Side              2983\n",
            "Name: bodypose, dtype: int64\n",
            "Baseline bodypose accuracy: 0.6176232225742282\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWoHc3PwiC-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one hot encoding of labels\n",
        "\n",
        "one_hot_df = pd.concat([\n",
        "    df[[\"image_path\"]],\n",
        "    pd.get_dummies(df.gender, prefix=\"gender\"),\n",
        "    pd.get_dummies(df.imagequality, prefix=\"imagequality\"),\n",
        "    pd.get_dummies(df.age, prefix=\"age\"),\n",
        "    pd.get_dummies(df.weight, prefix=\"weight\"),\n",
        "    pd.get_dummies(df.carryingbag, prefix=\"carryingbag\"),\n",
        "    pd.get_dummies(df.footwear, prefix=\"footwear\"),\n",
        "    pd.get_dummies(df.emotion, prefix=\"emotion\"),\n",
        "    pd.get_dummies(df.bodypose, prefix=\"bodypose\")\n",
        "    ], axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQMpteGniJ7Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_gender_cols_ = [col for col in one_hot_df.columns if col.startswith(\"gender\")]\n",
        "_imagequality_cols_ = [col for col in one_hot_df.columns if col.startswith(\"imagequality\")]\n",
        "_age_cols_ = [col for col in one_hot_df.columns if col.startswith(\"age\")]\n",
        "_weight_cols_ = [col for col in one_hot_df.columns if col.startswith(\"weight\")]\n",
        "_carryingbag_cols_ = [col for col in one_hot_df.columns if col.startswith(\"carryingbag\")]\n",
        "_footwear_cols_ = [col for col in one_hot_df.columns if col.startswith(\"footwear\")]\n",
        "_emotion_cols_ = [col for col in one_hot_df.columns if col.startswith(\"emotion\")]\n",
        "_bodypose_cols_ = [col for col in one_hot_df.columns if col.startswith(\"bodypose\")]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUVymgu5iPB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PersonImageDataGenerator(keras.utils.Sequence):\n",
        "\n",
        "  def __init__(self, data_df, image_size=(224, 224, 3), batch_size=32, shuffle=True, augment=None):\n",
        "    self.data_df = data_df\n",
        "    self.indices = data_df.index.tolist()\n",
        "    self.output_size = image_size\n",
        "    self.batch_size = batch_size\n",
        "    self.shuffle = shuffle\n",
        "    self.augment = augment\n",
        "    self.on_epoch_end()\n",
        "\n",
        "  def __len__(self):\n",
        "    # return number of batches (truncated)\n",
        "    return int(np.floor(len(self.data_df)/self.batch_size))\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    batch_df = self.data_df.iloc[idx*self.batch_size:(idx+1)*self.batch_size, :].copy()\n",
        "    indices = batch_df.index.tolist()\n",
        "    images = np.stack([cv2.resize(cv2.imread(batch_df.loc[rownum, \"image_path\"]), (self.output_size[0], self.output_size[1])) for rownum in indices])\n",
        "    _gender_cols_ = [col for col in batch_df.columns if col.startswith(\"gender\")]\n",
        "    target = {\n",
        "            \"gender_output\": batch_df[_gender_cols_].values,\n",
        "            \"image_quality_output\": batch_df[_imagequality_cols_].values,\n",
        "            \"age_output\": batch_df[_age_cols_].values,\n",
        "            \"weight_output\": batch_df[_weight_cols_].values,\n",
        "            \"bag_output\": batch_df[_carryingbag_cols_].values,\n",
        "            \"pose_output\": batch_df[_bodypose_cols_].values,\n",
        "            \"footwear_output\": batch_df[_footwear_cols_].values,\n",
        "            \"emotion_output\": batch_df[_emotion_cols_].values\n",
        "        }\n",
        "    if self.augment==None:\n",
        "      return images, target\n",
        "    else:\n",
        "      return np.stack([self.augment(image=x)[\"image\"] for x in images], axis=0), target\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    # shuffle dataset at the end of every epoch\n",
        "    if self.shuffle==True:\n",
        "      self.data_df = self.data_df.sample(frac=1).reset_index(drop=True)\n",
        "    else:\n",
        "      self.data_df = self.data_df.reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yclr6GDriu53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# callbacks\n",
        "\n",
        "class CyclicLR(keras.callbacks.Callback):\n",
        "    \n",
        "    def __init__(self,base_lr, max_lr, step_size, base_m, max_m, cyclical_momentum):\n",
        " \n",
        "        self.base_lr = base_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.base_m = base_m\n",
        "        self.max_m = max_m\n",
        "        self.cyclical_momentum = cyclical_momentum\n",
        "        self.step_size = step_size\n",
        "        \n",
        "        self.clr_iterations = 0.\n",
        "        self.cm_iterations = 0.\n",
        "        self.trn_iterations = 0.\n",
        "        self.history = {}\n",
        "        # self.on_epoch_end()\n",
        "        \n",
        "    def clr(self):\n",
        "        \n",
        "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
        "        \n",
        "        if cycle == 2:\n",
        "            x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)          \n",
        "            return self.base_lr-(self.base_lr-self.base_lr/100)*np.maximum(0,(1-x))\n",
        "        \n",
        "        else:\n",
        "            x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
        "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0,(1-x))\n",
        "    \n",
        "    def cm(self):\n",
        "        \n",
        "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
        "        \n",
        "        if cycle == 2:\n",
        "            \n",
        "            x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1) \n",
        "            return self.max_m\n",
        "        \n",
        "        else:\n",
        "            x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
        "            return self.max_m - (self.max_m-self.base_m)*np.maximum(0,(1-x))\n",
        "    def on_train_begin(self, logs={}):\n",
        "        logs = logs or {}\n",
        "\n",
        "        if self.clr_iterations == 0:\n",
        "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
        "        else:\n",
        "            K.set_value(self.model.optimizer.lr, self.clr())\n",
        "            \n",
        "        if self.cyclical_momentum == True:\n",
        "            if self.clr_iterations == 0:\n",
        "                K.set_value(self.model.optimizer.momentum, self.cm())\n",
        "            else:\n",
        "                K.set_value(self.model.optimizer.momentum, self.cm())\n",
        "            \n",
        "\n",
        "    def on_batch_begin(self, batch, logs=None):\n",
        "        \n",
        "        logs = logs or {}\n",
        "        self.trn_iterations += 1\n",
        "        self.clr_iterations += 1\n",
        "\n",
        "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
        "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
        "        \n",
        "        if self.cyclical_momentum == True:\n",
        "            self.history.setdefault('momentum', []).append(K.get_value(self.model.optimizer.momentum))\n",
        "\n",
        "        for k, v in logs.items():\n",
        "            self.history.setdefault(k, []).append(v)\n",
        "        \n",
        "        K.set_value(self.model.optimizer.lr, self.clr())\n",
        "        \n",
        "        if self.cyclical_momentum == True:\n",
        "            K.set_value(self.model.optimizer.momentum, self.cm())\n",
        "\n",
        "\n",
        "# print LR\n",
        "class printLR(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        lr = self.model.optimizer.lr\n",
        "        print(K.eval(lr))\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3r6P7VsjYZ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gug7Gs5jrdC",
        "colab_type": "code",
        "outputId": "0a5c3eb2-f907-4adc-dd1c-740f06c363b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(one_hot_df, test_size=0.15, random_state=42)\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "val_df = val_df.reset_index(drop=True)\n",
        "train_df.shape, val_df.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((11537, 28), (2036, 28))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XX1Kmazdjvgh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = [cv2.imread(train_df[\"image_path\"].iloc[x]) for x in range(len(train_df))]\n",
        "train_images = np.stack(train_images)\n",
        "labels = train_df[_gender_cols_].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWbO3KbPj0C1",
        "colab_type": "code",
        "outputId": "fce9f40c-cdf5-4a6d-c672-27e3059489b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11537, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKewCEZyj3F6",
        "colab_type": "code",
        "outputId": "35622390-2e04-4a51-bf1d-b3c7f8777696",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "labels.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11537, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOUi0gunj58d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_mean = np.mean(train_images, axis=(0, 1, 2))/255.0\n",
        "train_mean = np.array([0.16198463, 0.1628683 , 0.18274376])\n",
        "# train_std = np.std(train_images, axis=(0, 1, 2))/255.0\n",
        "train_std = np.array([0.25078711, 0.25332862, 0.27367283])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ksph58yj9MU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training parameters\n",
        "n = 2 #(number of resnet blocks)\n",
        "depth = n*9+2\n",
        "\n",
        "# Input image dimensions.\n",
        "input_shape = (224, 224, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37Ljxq3NpVJL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1ce2e059-2e9c-44ec-80b7-f5c6809bf147"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "APPROACH:\n",
        "\n",
        "Build backbone of the final model by training on the gender output.\n",
        "Use the first few layers of this model as the backbone, append the tower and head and train for each output to get the final model\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "########################################################################\n",
        "##########################   BACKBONE   ################################\n",
        "########################################################################\n",
        "\n",
        "# Start model definition.\n",
        "num_filters_in = 16\n",
        "num_res_blocks = n\n",
        "\n",
        "inputs = Input(shape=input_shape)   # size 224x224\n",
        "\n",
        "# x = MaxPool2D(pool_size=(2,2))(inputs)   # output 112x112\n",
        "\n",
        "x = Conv2D(16,\n",
        "          kernel_size=(3,3),\n",
        "          kernel_initializer='he_normal',\n",
        "          kernel_regularizer=l2(1e-4),\n",
        "          activation='relu')(inputs)  # output 110x110\n",
        "                                 # output 222x222\n",
        "x = MaxPool2D(pool_size=(2,2))(x)   # output 55x55\n",
        "                                    # output 111x111\n",
        "\n",
        "\n",
        "# v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
        "x = resnet_layer(inputs=x,\n",
        "                num_filters=num_filters_in,\n",
        "                conv_first=True)  # output of 54x54\n",
        "                                  # output 111x111\n",
        "\n",
        "# 3 stages - each stage has n residual blocks (each residual block has 3 convolution sets, the first one compresses except in the first stage)\n",
        "# Instantiate the stack of residual units\n",
        "for stage in range(3):\n",
        "    for res_block in range(num_res_blocks):\n",
        "        activation = 'relu'\n",
        "        batch_normalization = True\n",
        "        strides = 1\n",
        "        if stage == 0:\n",
        "            num_filters_out = num_filters_in * 4\n",
        "            if res_block == 0:  # first layer and first stage\n",
        "                activation = None\n",
        "                batch_normalization = False\n",
        "        else:\n",
        "            num_filters_out = num_filters_in * 2\n",
        "            if res_block == 0:  # first layer but not first stage\n",
        "                strides = 2    # downsample\n",
        "\n",
        "        # bottleneck residual unit\n",
        "        y = resnet_layer(inputs=x,\n",
        "                          num_filters=num_filters_in,\n",
        "                          kernel_size=1,\n",
        "                          strides=strides,\n",
        "                          activation=activation,\n",
        "                          batch_normalization=batch_normalization,\n",
        "                          conv_first=False)\n",
        "        # y = Dropout(0.2)(y)\n",
        "        y = resnet_layer(inputs=y,\n",
        "                          num_filters=num_filters_in,\n",
        "                          conv_first=False)\n",
        "        y = resnet_layer(inputs=y,\n",
        "                          num_filters=num_filters_out,\n",
        "                          kernel_size=1,\n",
        "                          conv_first=False)\n",
        "        # y = Dropout(0.2)(y)\n",
        "\n",
        "        if res_block == 0:\n",
        "            # linear projection residual shortcut connection to match\n",
        "            # changed dims\n",
        "            x = resnet_layer(inputs=x,\n",
        "                              num_filters=num_filters_out,\n",
        "                              kernel_size=1,\n",
        "                              strides=strides,\n",
        "                              activation=None,\n",
        "                              batch_normalization=False)\n",
        "        x = keras.layers.add([x, y])\n",
        "\n",
        "    num_filters_in = num_filters_out\n",
        "# output from resnet layers of 14x14\n",
        "                              #  28x28\n",
        "x = Conv2D(128,\n",
        "           kernel_size=1)(x) # output of 14x14\n",
        "                                        #  28x28\n",
        "x = Dropout(0.2)(x)\n",
        "x = MaxPool2D(pool_size=(2,2))(x)  #  14x14\n",
        "\n",
        "x = SeparableConv2D(filters = 160, kernel_size=3, activation = 'relu')(x) # 12x12\n",
        "\n",
        "x = SeparableConv2D(filters = 192, kernel_size=3, activation = 'relu')(x) # 10x10\n",
        "\n",
        "x = Conv2D(208,\n",
        "           kernel_size=(3,3), activation='relu')(x)   # output of 8x8\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "x = Conv2D(224,\n",
        "           kernel_size=(3,3), activation='relu')(x)   # output of 6x6\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "x = Conv2D(240,\n",
        "           kernel_size=(3,3), activation='relu')(x)   # output of 4x4\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "output = Dense(2, activation=\"softmax\", name=\"gender_output\")(x)\n",
        "\n",
        "# define model\n",
        "model = Model(\n",
        "    inputs=inputs, \n",
        "    outputs=output\n",
        ")\n",
        "\n",
        "opt = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
        "model.compile(\n",
        "    optimizer=opt,\n",
        "    loss=\"categorical_crossentropy\", \n",
        "    # loss_weights=loss_weights, \n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 222, 222, 16) 448         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 111, 111, 16) 0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 111, 111, 16) 2320        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 111, 111, 16) 64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 111, 111, 16) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 111, 111, 16) 272         activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 111, 111, 16) 64          conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 111, 111, 16) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 111, 111, 16) 2320        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 111, 111, 16) 64          conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 111, 111, 16) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 111, 111, 64) 1088        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 111, 111, 64) 1088        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 111, 111, 64) 0           conv2d_6[0][0]                   \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 111, 111, 64) 256         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 111, 111, 64) 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 111, 111, 16) 1040        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 111, 111, 16) 64          conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 111, 111, 16) 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 111, 111, 16) 2320        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 111, 111, 16) 64          conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 111, 111, 16) 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 111, 111, 64) 1088        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 111, 111, 64) 0           add_1[0][0]                      \n",
            "                                                                 conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 111, 111, 64) 256         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 111, 111, 64) 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 56, 56, 64)   4160        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 56, 56, 64)   256         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 56, 56, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 56, 56, 64)   256         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 56, 56, 64)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 56, 56, 128)  8320        add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 56, 56, 128)  8320        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 56, 56, 128)  0           conv2d_13[0][0]                  \n",
            "                                                                 conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 56, 56, 128)  512         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 56, 56, 128)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 56, 56, 64)   8256        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 56, 56, 64)   256         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 56, 56, 64)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 56, 56, 64)   36928       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 56, 56, 64)   256         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 56, 56, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 56, 56, 128)  8320        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 56, 56, 128)  0           add_3[0][0]                      \n",
            "                                                                 conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 56, 56, 128)  512         add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 56, 56, 128)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 28, 28, 128)  16512       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 28, 28, 128)  512         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 28, 28, 128)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 28, 28, 128)  512         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 28, 28, 128)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 28, 28, 256)  33024       add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 28, 28, 256)  33024       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 256)  0           conv2d_20[0][0]                  \n",
            "                                                                 conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 28, 28, 256)  1024        add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 28, 28, 256)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 28, 28, 128)  32896       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 28, 28, 128)  512         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 28, 28, 128)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 28, 28, 128)  512         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 28, 28, 128)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 28, 28, 256)  33024       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 28, 28, 256)  0           add_5[0][0]                      \n",
            "                                                                 conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 28, 28, 128)  32896       add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 28, 28, 128)  0           conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 128)  0           dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_1 (SeparableCo (None, 12, 12, 160)  21792       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_2 (SeparableCo (None, 10, 10, 192)  32352       separable_conv2d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 8, 8, 208)    359632      separable_conv2d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 8, 8, 208)    832         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 8, 8, 208)    0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 6, 6, 224)    419552      dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 6, 6, 224)    896         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 6, 6, 224)    0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 4, 4, 240)    484080      dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 4, 4, 240)    960         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 240)          0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "gender_output (Dense)           (None, 2)            482         global_average_pooling2d_1[0][0] \n",
            "==================================================================================================\n",
            "Total params: 1,926,290\n",
            "Trainable params: 1,921,970\n",
            "Non-trainable params: 4,320\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1sPQTZpkpC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set up training parameters\n",
        "training_batch_size=32\n",
        "epochs=50\n",
        "\n",
        "\n",
        "AUGMENTATIONS_TRAIN = Compose([\n",
        "    HorizontalFlip(p=0.5),\n",
        "    # Cutout(num_holes=1, max_h_size = int(input_shape[0]/5), max_w_size=int(input_shape[0]/5), p=1),\n",
        "    # Normalize(mean=tuple(train_mean), std=tuple(train_std), max_pixel_value=255.0, p=1),\n",
        "    Normalize(mean=(0, 0, 0), std=(1, 1, 1), max_pixel_value=255.0, p=1),\n",
        "    ShiftScaleRotate(\n",
        "        shift_limit=0.0625, scale_limit=0.1, \n",
        "        rotate_limit=15, border_mode=cv2.BORDER_REFLECT_101, p=0.3)\n",
        "])\n",
        "\n",
        "AUGMENTATIONS_VAL = Compose([\n",
        "    # CLAHE(p=1.0, clip_limit=2.0),\n",
        "    # Normalize(mean=tuple(train_mean), std=tuple(train_std), max_pixel_value=255.0, p=1.0)\n",
        "    # , \n",
        "    Normalize(mean=(0, 0, 0), std=(1, 1, 1), max_pixel_value=255.0, p=1)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_lJpndOqZW7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create train and validation data generators\n",
        "train_genr = PersonImageDataGenerator(train_df, batch_size=training_batch_size, shuffle=True, augment=AUGMENTATIONS_TRAIN)\n",
        "valid_genr = PersonImageDataGenerator(val_df, batch_size=64, shuffle=False, augment=AUGMENTATIONS_VAL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJyJXxMtmjRf",
        "colab_type": "code",
        "outputId": "9191dea3-a4e9-4d2e-eba2-14c88e7450f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "# get number of output units from data\n",
        "images, targets = next(iter(train_genr))\n",
        "i=9\n",
        "cv2_imshow(images[i]*255)\n",
        "print(_gender_cols_)\n",
        "print(targets[\"gender_output\"][i])\n",
        "print(_imagequality_cols_)\n",
        "print(targets[\"image_quality_output\"][i])\n",
        "print(_age_cols_)\n",
        "print(targets[\"age_output\"][i])\n",
        "print(_weight_cols_)\n",
        "print(targets[\"weight_output\"][i])\n",
        "print(_carryingbag_cols_)\n",
        "print(targets[\"bag_output\"][i])\n",
        "print(_footwear_cols_)\n",
        "print(targets[\"footwear_output\"][i])\n",
        "print(_emotion_cols_)\n",
        "print(targets[\"emotion_output\"][i])\n",
        "print(_bodypose_cols_)\n",
        "print(targets[\"pose_output\"][i])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOAAAADgCAIAAACVT/22AACAhklEQVR4nOz9Z7CkaXYeiJ1zXvOZ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\nvwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=224x224 at 0x7FBB1C8876A0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "['gender_female', 'gender_male']\n",
            "[0 1]\n",
            "['imagequality_Average', 'imagequality_Bad', 'imagequality_Good']\n",
            "[1 0 0]\n",
            "['age_15-25', 'age_25-35', 'age_35-45', 'age_45-55', 'age_55+']\n",
            "[0 1 0 0 0]\n",
            "['weight_normal-healthy', 'weight_over-weight', 'weight_slightly-overweight', 'weight_underweight']\n",
            "[1 0 0 0]\n",
            "['carryingbag_Daily/Office/Work Bag', 'carryingbag_Grocery/Home/Plastic Bag', 'carryingbag_None']\n",
            "[0 0 1]\n",
            "['footwear_CantSee', 'footwear_Fancy', 'footwear_Normal']\n",
            "[0 0 1]\n",
            "['emotion_Angry/Serious', 'emotion_Happy', 'emotion_Neutral', 'emotion_Sad']\n",
            "[0 0 1 0]\n",
            "['bodypose_Back', 'bodypose_Front-Frontish', 'bodypose_Side']\n",
            "[0 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHkXIRQtoLpl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = SGD(lr=0.005, momentum=0.9, nesterov=True)\n",
        "model.compile(\n",
        "    optimizer=opt,\n",
        "    loss=\"categorical_crossentropy\", \n",
        "    # loss_weights=loss_weights, \n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRw1xQ1SrCMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_suffix = 'res20'\n",
        "# Prepare model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'gdrive', 'My Drive', 'eip4_assignment5_modelweights', '29dec_earlystart')\n",
        "model_name = 'eip4a5_model_%s.{epoch:03d}.h5' % model_suffix\n",
        "\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(monitor='acc',\n",
        "                               mode='auto',\n",
        "                               factor=np.sqrt(0.1),\n",
        "                               cooldown=1,\n",
        "                               patience=3,\n",
        "                               min_delta=0.001,\n",
        "                               min_lr=0.5e-6,\n",
        "                               verbose=1)\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JuZ02TDsb3o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bb92bef1-ebfe-489a-c8fc-945a85d271fd"
      },
      "source": [
        "# Train the backbone model\n",
        "model.fit_generator(train_genr,\n",
        "                    validation_data = valid_genr,\n",
        "                    use_multiprocessing=True,\n",
        "                    workers=6, \n",
        "                    epochs=20,\n",
        "                    verbose=1,\n",
        "                    callbacks=callbacks)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/20\n",
            "359/360 [============================>.] - ETA: 0s - loss: 1.1103 - acc: 0.6067\n",
            "360/360 [==============================] - 66s 184ms/step - loss: 1.1101 - acc: 0.6068 - val_loss: 1.1370 - val_acc: 0.5766\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.57661, saving model to /content/gdrive/My Drive/eip4_assignment5_modelweights/29dec_earlystart/eip4a5_model_res20.001.h5\n",
            "Epoch 2/20\n",
            "360/360 [==============================] - 52s 145ms/step - loss: 1.0533 - acc: 0.6531 - val_loss: 1.1042 - val_acc: 0.5968\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.57661 to 0.59677, saving model to /content/gdrive/My Drive/eip4_assignment5_modelweights/29dec_earlystart/eip4a5_model_res20.002.h5\n",
            "Epoch 3/20\n",
            "360/360 [==============================] - 53s 146ms/step - loss: 1.0198 - acc: 0.6809 - val_loss: 1.0452 - val_acc: 0.6668\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.59677 to 0.66683, saving model to /content/gdrive/My Drive/eip4_assignment5_modelweights/29dec_earlystart/eip4a5_model_res20.003.h5\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.57661 to 0.59677, saving model to /content/gdrive/My Drive/eip4_assignment5_modelweights/29dec_earlystart/eip4a5_model_res20.002.h5\n",
            "Epoch 4/20\n",
            "360/360 [==============================] - 53s 147ms/step - loss: 0.9927 - acc: 0.7078 - val_loss: 0.9966 - val_acc: 0.6900\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.66683 to 0.69002, saving model to /content/gdrive/My Drive/eip4_assignment5_modelweights/29dec_earlystart/eip4a5_model_res20.004.h5\n",
            "Epoch 5/20\n",
            "360/360 [==============================] - 53s 146ms/step - loss: 0.9723 - acc: 0.7196 - val_loss: 0.9555 - val_acc: 0.7329\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.69002 to 0.73286, saving model to /content/gdrive/My Drive/eip4_assignment5_modelweights/29dec_earlystart/eip4a5_model_res20.005.h5\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.66683 to 0.69002, saving model to /content/gdrive/My Drive/eip4_assignment5_modelweights/29dec_earlystart/eip4a5_model_res20.004.h5\n",
            "Epoch 6/20\n",
            "360/360 [==============================] - 52s 145ms/step - loss: 0.9397 - acc: 0.7491 - val_loss: 0.9292 - val_acc: 0.7560\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.73286 to 0.75605, saving model to /content/gdrive/My Drive/eip4_assignment5_modelweights/29dec_earlystart/eip4a5_model_res20.006.h5\n",
            "Epoch 7/20\n",
            "360/360 [==============================] - 53s 147ms/step - loss: 0.9148 - acc: 0.7626 - val_loss: 0.9577 - val_acc: 0.7263\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.75605\n",
            "Epoch 8/20\n",
            "359/360 [============================>.] - ETA: 0s - loss: 0.8916 - acc: 0.7772\n",
            "Epoch 00007: val_acc did not improve from 0.75605\n",
            "360/360 [==============================] - 53s 148ms/step - loss: 0.8916 - acc: 0.7772 - val_loss: 0.9347 - val_acc: 0.7540\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.75605\n",
            "Epoch 9/20\n",
            "359/360 [============================>.] - ETA: 0s - loss: 0.8703 - acc: 0.7846Epoch 9/20\n",
            "360/360 [==============================] - 53s 148ms/step - loss: 0.8705 - acc: 0.7846 - val_loss: 1.0601 - val_acc: 0.7082\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.75605\n",
            "Epoch 10/20\n",
            "360/360 [==============================] - 53s 148ms/step - loss: 0.8436 - acc: 0.7995 - val_loss: 0.9029 - val_acc: 0.7550\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.75605\n",
            "Epoch 11/20\n",
            "360/360 [==============================] - 53s 148ms/step - loss: 0.8206 - acc: 0.8119 - val_loss: 0.9462 - val_acc: 0.7555\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.75605\n",
            "Epoch 12/20\n",
            "359/360 [============================>.] - ETA: 0s - loss: 0.8054 - acc: 0.8222Epoch 12/20\n",
            "360/360 [==============================] - 54s 149ms/step - loss: 0.8054 - acc: 0.8222 - val_loss: 0.8526 - val_acc: 0.7843\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.75605 to 0.78427, saving model to /content/gdrive/My Drive/eip4_assignment5_modelweights/29dec_earlystart/eip4a5_model_res20.012.h5\n",
            "Epoch 13/20\n",
            "360/360 [==============================] - 53s 146ms/step - loss: 0.7992 - acc: 0.8189 - val_loss: 0.8860 - val_acc: 0.7631\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.78427\n",
            "Epoch 14/20\n",
            "360/360 [==============================] - 53s 148ms/step - loss: 0.7911 - acc: 0.8258 - val_loss: 0.8088 - val_acc: 0.8165\n",
            "\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.78427 to 0.81653, saving model to /content/gdrive/My Drive/eip4_assignment5_modelweights/29dec_earlystart/eip4a5_model_res20.014.h5\n",
            "Epoch 15/20\n",
            "360/360 [==============================] - 53s 146ms/step - loss: 0.7770 - acc: 0.8344 - val_loss: 0.9308 - val_acc: 0.7550\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.81653\n",
            "Epoch 16/20\n",
            "360/360 [==============================] - 54s 149ms/step - loss: 0.7599 - acc: 0.8434 - val_loss: 0.8256 - val_acc: 0.8054\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.81653\n",
            "Epoch 17/20\n",
            "360/360 [==============================] - 54s 150ms/step - loss: 0.7519 - acc: 0.8453 - val_loss: 0.8541 - val_acc: 0.8039\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.81653\n",
            "Epoch 17/20\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.81653\n",
            "Epoch 18/20\n",
            "360/360 [==============================] - 55s 152ms/step - loss: 0.7401 - acc: 0.8472 - val_loss: 0.7975 - val_acc: 0.8170\n",
            "\n",
            "Epoch 00018: val_acc improved from 0.81653 to 0.81704, saving model to /content/gdrive/My Drive/eip4_assignment5_modelweights/29dec_earlystart/eip4a5_model_res20.018.h5\n",
            "Epoch 19/20\n",
            "360/360 [==============================] - 54s 149ms/step - loss: 0.7290 - acc: 0.8520 - val_loss: 0.7749 - val_acc: 0.8357\n",
            "\n",
            "Epoch 00019: val_acc improved from 0.81704 to 0.83569, saving model to /content/gdrive/My Drive/eip4_assignment5_modelweights/29dec_earlystart/eip4a5_model_res20.019.h5\n",
            "Epoch 20/20\n",
            "359/360 [============================>.] - ETA: 0s - loss: 0.7222 - acc: 0.8558\n",
            "360/360 [==============================] - 54s 149ms/step - loss: 0.7222 - acc: 0.8558 - val_loss: 0.8686 - val_acc: 0.7954\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.83569\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbb1c975358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woAaBqtszAlV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "model_gender = load_model(\"/content/gdrive/My Drive/eip4_assignment5_modelweights/29dec_earlystart/eip4a5_model_res20.018.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEg7MB6ZRiHV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f4448683-894d-458f-fdad-45c5ea70fd51"
      },
      "source": [
        "model_gender.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 222, 222, 16) 448         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 111, 111, 16) 0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 111, 111, 16) 2320        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 111, 111, 16) 64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 111, 111, 16) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 111, 111, 16) 272         activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 111, 111, 16) 64          conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 111, 111, 16) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 111, 111, 16) 2320        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 111, 111, 16) 64          conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 111, 111, 16) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 111, 111, 64) 1088        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 111, 111, 64) 1088        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 111, 111, 64) 0           conv2d_6[0][0]                   \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 111, 111, 64) 256         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 111, 111, 64) 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 111, 111, 16) 1040        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 111, 111, 16) 64          conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 111, 111, 16) 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 111, 111, 16) 2320        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 111, 111, 16) 64          conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 111, 111, 16) 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 111, 111, 64) 1088        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 111, 111, 64) 0           add_1[0][0]                      \n",
            "                                                                 conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 111, 111, 64) 256         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 111, 111, 64) 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 56, 56, 64)   4160        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 56, 56, 64)   256         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 56, 56, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 56, 56, 64)   256         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 56, 56, 64)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 56, 56, 128)  8320        add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 56, 56, 128)  8320        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 56, 56, 128)  0           conv2d_13[0][0]                  \n",
            "                                                                 conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 56, 56, 128)  512         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 56, 56, 128)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 56, 56, 64)   8256        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 56, 56, 64)   256         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 56, 56, 64)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 56, 56, 64)   36928       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 56, 56, 64)   256         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 56, 56, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 56, 56, 128)  8320        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 56, 56, 128)  0           add_3[0][0]                      \n",
            "                                                                 conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 56, 56, 128)  512         add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 56, 56, 128)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 28, 28, 128)  16512       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 28, 28, 128)  512         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 28, 28, 128)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 28, 28, 128)  512         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 28, 28, 128)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 28, 28, 256)  33024       add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 28, 28, 256)  33024       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 256)  0           conv2d_20[0][0]                  \n",
            "                                                                 conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 28, 28, 256)  1024        add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 28, 28, 256)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 28, 28, 128)  32896       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 28, 28, 128)  512         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 28, 28, 128)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 28, 28, 128)  512         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 28, 28, 128)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 28, 28, 256)  33024       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 28, 28, 256)  0           add_5[0][0]                      \n",
            "                                                                 conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 28, 28, 128)  32896       add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 28, 28, 128)  0           conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 128)  0           dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_1 (SeparableCo (None, 12, 12, 160)  21792       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_2 (SeparableCo (None, 10, 10, 192)  32352       separable_conv2d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 8, 8, 208)    359632      separable_conv2d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 8, 8, 208)    832         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 8, 8, 208)    0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 6, 6, 224)    419552      dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 6, 6, 224)    896         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 6, 6, 224)    0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 4, 4, 240)    484080      dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 4, 4, 240)    960         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 240)          0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "gender_output (Dense)           (None, 2)            482         global_average_pooling2d_1[0][0] \n",
            "==================================================================================================\n",
            "Total params: 1,926,290\n",
            "Trainable params: 1,921,970\n",
            "Non-trainable params: 4,320\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQW08jz4SDia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}